## 主要作用

 **[Attention Mechanism可以帮助模型对输入的X每个部分赋予不同的权重，抽取出更加关键及重要的信息，使模型做出更加准确的判断，同时不会对模型的计算和存储带来更大的开销。](http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247484312&idx=1&sn=712df7b7166561198d52659c486c5ece&chksm=97a0c84ca0d7415aee9ef00f104665ccf8cf41b6171c655c667bb61351db3586b2f63dc2685c&scene=21#wechat_redirect)** 

### encoder-decoder

encoder-decoder模型虽然非常经典，但是局限性也非常大。最大的局限性就在于编码和解码之间的唯一联系就是一个固定长度的语义向量C。也就是说，编码器要将整个序列的信息压缩进一个固定长度的向量中去。但是这样做有两个弊端，一是语义向量无法完全表示整个序列的信息，二是先输入的内容携带的信息会被后输入的信息稀释掉。输入序列越长，这个现象就越严重。这就使得在解码的时候一开始就没有获得输入序列足够的信息， 那么解码时准确率就要打一定折扣。

为了解决上述问题，在 Seq2Seq出现一年之后，Attention模型被提出了。该模型在产生输出的时候，会产生一个注意力范围来表示接下来输出的时候要重点关注输入序列的哪些部分，然后根据关注的区域来产生下一个输出，如此反复。attention 和人的一些行为特征有一定相似之处，人在看一段话的时候，通常只会重点注意具有信息量的词，而非全部词，即人会赋予每个词的注意力权重不同。attention 模型虽然增加了模型的训练难度，但提升了文本生成的效果。模型的大概示意图如下。

### 经典的attention模型

  每一个c会自动去选取与当前所要输出的y最合适的上下文信息。具体来说，我们用 aij 衡量编码中第j阶段的hj和解码时第i阶段的相关性，最终Decoder中第i阶段的输入的上下文信息 ci 就来自于所有 hj对 aij的加权和。



## 原理

[参考网址：深度学习中Attention Mechanism详细介绍：原理、分类及应用](https://blog.csdn.net/u010417185/article/details/83090766)



当我们人在看一样东西的时候，我们当前时刻关注的一定是我们当前正在看的这样东西的某一地方，换句话说，当我们目光移到别处时，注意力随着目光的移动也在转移，这意味着，当人们注意到某个目标或某个场景时，该目标内部以及该场景内每一处空间位置上的注意力分布是不一样的。这一点在如下情形下同样成立：当我们试图描述一件事情，我们当前时刻说到的单词和句子和正在描述的该事情的对应某个片段最相关，而其他部分随着描述的进行，相关性也在不断地改变。从上述两种情形，读者可以看出，对于Attention的作用角度出发，我们就可以从两个角度来分类Attention种类：空间注意力和时间注意力，即Spatial Attention 和Temporal Attention。这种分类更多的是从应用层面上，而从Attention的作用方法上，可以将其分为Soft Attention和Hard Attention，这既我们所说的，Attention输出的向量分布是一种one-hot的独热分布还是soft的软分布，这直接影响对于上下文信息的选择作用。

  

